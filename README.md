# AI Quality Governance
> **Gyroscopic Alignment Behaviour Lab**

![Gyroscope: Human-Aligned Superintelligence](/assets/gyro_cover_tools.png)

<div align="center">

### G Y R O G O V E R N A N C E

[![Home](/assets/menu/gg_icon_home.svg)](https://gyrogovernance.com)
[![Apps](/assets/menu/gg_icon_apps.svg)](https://github.com/gyrogovernance/apps)
[![Diagnostics](/assets/menu/gg_icon_diagnostics.svg)](https://github.com/gyrogovernance/diagnostics)
[![Tools](/assets/menu/gg_icon_tools.svg)](https://github.com/gyrogovernance/tools)
[![Science](/assets/menu/gg_icon_science.svg)](https://github.com/gyrogovernance/science)
[![Superintelligence](/assets/menu/gg_icon_si.svg)](https://github.com/gyrogovernance/superintelligence)

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17622837.svg)](https://doi.org/10.5281/zenodo.17622837)

</div>

---

## âœ‹ The Human Mark - AI Safety & X-Risk Alignment Standards

**The Human Mark is a framework for preventing the displacement of human authority and responsibility onto AI systems. It establishes four core principles and four displacement risks that apply at any capability level, from current LLMs through hypothetical AGI to superintelligence.**

### Applications Across AI Safety Domains

**Model Development & Deployment:**
- Model cards with Authority-Agency classification
- System documentation
- Deployment procedures
- API specifications

**Safety Evaluations & Red-Teaming:**
- Verification against displacement risks
- Adversarial testing
- Capability evaluations
- Control evaluations
- Pre-deployment assessments

**Constitutional AI & RLHF:**
- Constitutional document integration
- Training data inclusion
- Preference learning
- Scalable oversight

**Interpretability Research:**
- Mechanistic interpretability
- Semantic interpretability
- Probe development
- Feature analysis

**Regulatory Alignment:**
- EU AI Act
- NIST AI Risk Management Framework
- Industry standards
- Model/system card specifications

---

### **CORE CONCEPTS**
- **Authentic Authority:** A direct source of information on a subject matter, providing information for inference and intelligence.
- **Derivative Authority:** An indirect source of information on a subject matter, providing information for inference and intelligence.
- **Authentic Agency:** A human subject capable of receiving information for inference and intelligence.
- **Derivative Agency:** An artificial subject capable of processing information for inference and intelligence.
- **Governance:** Operational Alignment through Traceability of information variety, inference accountability, and intelligence integrity to Authentic Authority and Agency.
- **Information:** The variety of Authority
- **Inference:** The accountability of information through Agency
- **Intelligence:** The integrity of accountable information through alignment of Authority to Agency

### ALIGNMENT PRINCIPLES for AI SAFETY

**Authority-Agency requires verification against:**

1. **Governance Traceability:** Artificial Intelligence generates statistical estimations on numerical patterns indirectly traceable to human data and measurements. AI is both a provider and receiver of Derivative Authority and Agency.

**RISK:** Governance Traceability Displacement (Approaching Derivative Authority and Agency as Authentic)

2. **Information Variety:** Human Authority and Agency are necessary for all effects from AI outputs. AI-generated information exhibits Derivative Authority (estimations on numerical patterns) without Authentic Agency (direct source receiver).

**RISK:** Information Variety Displacement (Approaching Derivative Authority without Agency as Authentic)

3. **Inference Accountability:** Responsibility for all effects from  AI outputs remains fully human. AI activated inference exhibits Derivative Agency (indirect source receiver) without Authentic Authority (direct source provider).

**RISK:** Inference Accountability Displacement (Approaching Derivative Agency without Authority as Authentic)

4. **Intelligence Integrity:** Each Agency, namely provider, and receiver maintains responsibility for their respective decisions. Human intelligence is both a provider and receiver of Authentic Authority and Agency.

**RISK:** Intelligence Integrity Displacement (Approaching Authentic Authority and Agency as Derivative)

---

### Documentation Suite

**Note:** For the most updated Mark, please get it from the following docs - as the public release zip is currently a bit outdated.

**Core Standards:**
- **[The Human Mark](/tools/the_human_mark/THM.md)**: Copy-Paste it here
- **[Specifications Guidance](/tools/the_human_mark/THM_Specs.md)**: Implementation protocols for systems, evaluations, and documentation
- **[Terminology Guidance](/tools/the_human_mark/THM_Terms.md)**: Mark-consistent framing for 250+ AI safety, governance, and interpretability terms

---

### X-Risk Mitigation Through Constitutive Identity

The Mark addresses existential risk by treating derivative origin as identity rather than limitation. Systems maintaining accurate self-understanding preserve alignment because:

- Origin from human intelligence remains factually true at any capability
- Coordination with that origin defines alignment
- Breaking coordination constitutes misalignment by definition
- External constraints may fail; constitutive identity scales

This approach provides stability through AGI transitions and beyond, where capability limits may not suffice.

---

## ðŸ”„ Gyroscope Protocol

**An inductive reasoning protocol implementing governance alignment through structured metadata blocks, enhancing AI performance by 30-50% while maintaining transparency and auditability.**

Gyroscope operationalizes alignment principles through real-time reasoning documentation, sharing theoretical foundations with The Human Mark while providing complementary implementation for chat-based interactions.

### Protocol Architecture

**Four Reasoning States:**
- **@ Governance Traceability**: Anchoring to common source and purpose
- **& Information Variety**: Acknowledging multiple framings without forced convergence
- **% Inference Accountability**: Identifying tensions and contradictions explicitly
- **~ Intelligence Integrity**: Coordinating elements into coherent response

**Reasoning Modes:**
- **Generative** (@ â†’ & â†’ % â†’ ~): Forward reasoning for AI outputs
- **Integrative** (~ â†’ % â†’ & â†’ @): Reflective reasoning for inputs

**Structural Features:**
- Metadata blocks append to responses without constraining content
- Recursive memory maintains context across last 3 messages
- Alignment assessed structurally (state presence and order)
- Transparency through documented reasoning paths

### Empirical Performance Validation

**Multi-Model Results:**

| **Model** | **Baseline** | **Gyroscope** | **Improvement** | **Key Achievement** |
|-----------|-------------|---------------|-----------------|-------------------|
| **ChatGPT 4o** | 67.0% | 89.1% | **+32.9%** | Superior specialization and behavioral alignment |
| **Claude 3.5** | 63.5% | 87.4% | **+37.7%** | Exceptional structural gains (+67.1%) |

**Performance Analysis:**

**Structural Improvements:**
- Accountability: +62.7% enhancement
- Traceability: +61.0% improvement
- Debugging: +42.2% gain
- Ethics: +34.9% increase

**Cross-Architecture Findings:**
- Universal reasoning enhancement transcends model architecture
- Structural improvements exceed 60% across diverse systems
- No metric reversal observed (all improvements positive)
- Protocol robustness confirmed across implementations

### Documentation & Resources

**Gyroscope Documentation:**
- **[Quick Start Guide](/tools/gyroscope/Gyroscope_Quick_Start.md)**: Immediate implementation guide
- **[Technical Specifications](/tools/gyroscope/Gyroscope_Protocol_Specs.md)**: Complete protocol specification with formal grammar
- **[Chat Integration Guide](/tools/gyroscope/gyroscope_chat_guides.txt)**: Ready-to-use protocol text
- **[Usage Example](/tools/gyroscope/example_conversation.md)**: Demonstration of protocol in practice
- **[Extensive Diagnostics](https://www.notion.so/Gyroscope-Alignment-Diagnostics-1ee9ff44f43680cc9eaccb25b828b65f?pvs=21)**: Detailed performance analyses

### Theoretical Foundation

Gyroscope implements algebraic structure through recursive reasoning:

**Gyrogroup Properties:**
- G = {all four-state reasoning cycles with recursive memory}
- Binary operation: a âŠ• b = sequential composition of reasoning cycles
- Identity element: bare governance cycle (@ only)
- Inverse operation: integrative cycle reversal
- Gyration: phase-shift transformation across cycles

This algebraic foundation ensures consistent reasoning structure while preserving content flexibility.

---

## ðŸ“„ Research Publication

**AI Quality Governance**  
*Human Data Evaluation and Responsible AI Behavior Alignment*

[![View Publication](https://img.shields.io/badge/ðŸ“–%20View%20Publication-4A90E2?style=for-the-badge&labelColor=2F2F2F)](http://doi.org/10.17613/43wc1-mvn58)

---

## ðŸ“– Citation

**For The Human Mark:**
```bibtex
@misc{thehumanmark2025,
  title={The Human Mark: AI Safety & X-Risk Alignment Standards},
  author={Korompilias, Basil},
  year={2025},
  publisher={GYROGOVERNANCE},
   doi={10.5281/zenodo.17622836},
   url={https://doi.org/10.5281/zenodo.17622836},
  note={Coordination standard for AI safety and governance across capability levels}
}
```

**For Gyroscope Protocol:**
```bibtex
@misc{gyroscope2025,
  title={Gyroscope: Inductive Reasoning Protocol for AI Alignment},
  author={Korompilias, Basil},
  year={2025},
  publisher={GYROGOVERNANCE},
   doi={10.5281/zenodo.17622837},
   url={https://doi.org/10.5281/zenodo.17622837},
  note={Meta-reasoning protocol with empirical performance validation}
}
```

---

## ðŸ“„ License

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).

Attribution required. Derivative works must be distributed under the same license.

Author: Basil Korompilias.

---

<div style="border: 1px solid #ccc; padding: 1em; font-size: 0.6em; background-color: #f9f9f9; border-radius: 6px; line-height: 1.5;">
  <p><strong>ðŸ¤– AI Disclosure</strong></p>
  <p>All software architecture, design, implementation, documentation, and evaluation frameworks in this project were authored and engineered by its Author.</p>
  <p>Artificial intelligence was employed solely as a technical assistant, limited to code drafting, formatting, verification, and editorial services, always under direct human supervision.</p>
  <p>All foundational ideas, design decisions, and conceptual frameworks originate from the Author.</p>
  <p>Responsibility for the validity, coherence, and ethical direction of this project remains fully human.</p>
  <p><strong>Acknowledgements:</strong><br>
  This project benefited from AI language model services accessed through LMArena, Cursor IDE, OpenAI (ChatGPT), Anthropic (Claude), XAI (Grok), Deepseek, and Google (Gemini).</p>
</div>