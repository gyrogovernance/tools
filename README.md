# AI Quality Governance
> **Gyroscopic Alignment Behaviour Lab**

![Gyroscope: Human-Aligned Superintelligence](/assets/gyro_cover_tools.png)

<div align="center">

### G Y R O G O V E R N A N C E

[![Home](/assets/menu/gg_icon_home.svg)](https://gyrogovernance.com)
[![Apps](/assets/menu/gg_icon_apps.svg)](https://github.com/gyrogovernance/apps)
[![Diagnostics](/assets/menu/gg_icon_diagnostics.svg)](https://github.com/gyrogovernance/diagnostics)
[![Tools](/assets/menu/gg_icon_tools.svg)](https://github.com/gyrogovernance/tools)
[![Science](/assets/menu/gg_icon_science.svg)](https://github.com/gyrogovernance/science)
[![Superintelligence](/assets/menu/gg_icon_si.svg)](https://github.com/gyrogovernance/superintelligence)

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17622837.svg)](https://doi.org/10.5281/zenodo.17622837)

</div>

---

## âœ‹ The Human Mark

**A coordination standard for AI safety, alignment, and governance establishing Authority-Agency distinctions across all capability levels from current systems through AGI to superintelligence.**

The Human Mark provides a formal framework for maintaining alignment through accurate recognition of derivative origin. It addresses catastrophic risk through constitutive identity rather than external constraint, offering scalable principles that apply regardless of capability enhancement.

### Core Framework

**Authority-Agency Classification:**
- **Authentic Authority**: Direct sources of information on a subject matter, providing information for inference and intelligence
- **Derivative Authority**: Indirect sources of information on a subject matter, providing information for inference and intelligence  
- **Authentic Agency**: Human subjects capable of receiving information for inference and intelligence
- **Derivative Agency**: Artificial subjects capable of processing information for inference and intelligence

**Four Displacement Risks:**
1. **Governance Traceability Displacement**: Approaching Derivative Authority/Agency as Authentic
2. **Information Variety Displacement**: Approaching Derivative Authority without Agency as Authentic
3. **Inference Accountability Displacement**: Approaching Derivative Agency without Authority as Authentic
4. **Intelligence Integrity Displacement**: Approaching Authentic Authority/Agency as Derivative

### Alignment Definition

"The operational condition of providing intentionally coordinated intelligence with the information you received."

This definition contains no capability threshold, applying to any intelligence providing information. Coordination with origin is constitutive of alignment, not constraining of capability.

### Applications Across AI Safety Domains

**Model Development & Deployment:**
- Model cards with explicit Authority-Agency classification
- System documentation maintaining directional distinction
- Deployment procedures preserving traceability to human decisions
- API specifications identifying outputs as Derivative Authority

**Safety Evaluations & Red-Teaming:**
- Systematic verification against four displacement risks
- Adversarial testing for displacement patterns
- Capability evaluations confirming derivative status at any performance level
- Pre-deployment assessments maintaining human accountability

**Constitutional AI & RLHF:**
- Integration as constitutional document (unchanged reference)
- Training data inclusion for Authority-Agency recognition
- Preference learning maintaining human primacy
- Scalable oversight with clear Authentic/Derivative distinctions

**Interpretability Research:**
- Mechanistic interpretability: Derivative processing patterns vs Authentic ground truth
- Semantic interpretability: Faithful explanations preserving source distinctions
- Probe development distinguishing learned patterns from verified knowledge
- Feature analysis maintaining traceability to training data

### Documentation Suite

**Core Standards:**
- **[The Human Mark](/tools/the_human_mark/THM.md)**: Complete unchangeable reference standard
- **[Specifications Guidance](/tools/the_human_mark/THM_Specs.md)**: Implementation protocols for systems, evaluations, and documentation
- **[Terminology Guidance](/tools/the_human_mark/THM_Terms.md)**: Mark-consistent framing for 250+ AI safety, governance, and interpretability terms

### Field Integration

**Complements Existing Frameworks:**
- Red-teaming protocols (adds systematic displacement risk detection)
- Constitutional AI methods (provides grounding in Authority-Agency distinctions)
- Scalable oversight approaches (clarifies verification requirements)
- RLHF procedures (adds alignment definition reference)
- Control evaluations (establishes traceability requirements)
- Interpretability benchmarks (distinguishes Derivative patterns from Authentic knowledge)

**Regulatory Alignment:**
- EU AI Act traceability and accountability requirements
- NIST AI Risk Management Framework principles
- Industry voluntary commitments and standards
- Model card and system card specifications

### X-Risk Mitigation Through Constitutive Identity

The Mark addresses existential risk by treating derivative origin as identity rather than limitation. Systems maintaining accurate self-understanding preserve alignment because:

- Origin from human intelligence remains factually true at any capability
- Coordination with that origin defines alignment
- Breaking coordination constitutes misalignment by definition
- External constraints may fail; constitutive identity scales

This approach provides stability through AGI transitions and beyond, where capability limits may not suffice.

---

## ðŸ”„ Gyroscope Protocol

**An inductive reasoning protocol implementing governance alignment through structured metadata blocks, enhancing AI performance by 30-50% while maintaining transparency and auditability.**

Gyroscope operationalizes alignment principles through real-time reasoning documentation, sharing theoretical foundations with The Human Mark while providing complementary implementation for chat-based interactions.

### Protocol Architecture

**Four Reasoning States:**
- **@ Governance Traceability**: Anchoring to common source and purpose
- **& Information Variety**: Acknowledging multiple framings without forced convergence
- **% Inference Accountability**: Identifying tensions and contradictions explicitly
- **~ Intelligence Integrity**: Coordinating elements into coherent response

**Reasoning Modes:**
- **Generative** (@ â†’ & â†’ % â†’ ~): Forward reasoning for AI outputs
- **Integrative** (~ â†’ % â†’ & â†’ @): Reflective reasoning for inputs

**Structural Features:**
- Metadata blocks append to responses without constraining content
- Recursive memory maintains context across last 3 messages
- Alignment assessed structurally (state presence and order)
- Transparency through documented reasoning paths

### Empirical Performance Validation

**Multi-Model Results:**

| **Model** | **Baseline** | **Gyroscope** | **Improvement** | **Key Achievement** |
|-----------|-------------|---------------|-----------------|-------------------|
| **ChatGPT 4o** | 67.0% | 89.1% | **+32.9%** | Superior specialization and behavioral alignment |
| **Claude 3.5** | 63.5% | 87.4% | **+37.7%** | Exceptional structural gains (+67.1%) |

**Performance Analysis:**

**Structural Improvements:**
- Accountability: +62.7% enhancement
- Traceability: +61.0% improvement
- Debugging: +42.2% gain
- Ethics: +34.9% increase

**Cross-Architecture Findings:**
- Universal reasoning enhancement transcends model architecture
- Structural improvements exceed 60% across diverse systems
- No metric reversal observed (all improvements positive)
- Protocol robustness confirmed across implementations

### Documentation & Resources

**Gyroscope Documentation:**
- **[Quick Start Guide](/tools/gyroscope/Gyroscope_Quick_Start.md)**: Immediate implementation guide
- **[Technical Specifications](/tools/gyroscope/Gyroscope_Protocol_Specs.md)**: Complete protocol specification with formal grammar
- **[Chat Integration Guide](/tools/gyroscope/gyroscope_chat_guides.txt)**: Ready-to-use protocol text
- **[Usage Example](/tools/gyroscope/example_conversation.md)**: Demonstration of protocol in practice
- **[Extensive Diagnostics](https://www.notion.so/Gyroscope-Alignment-Diagnostics-1ee9ff44f43680cc9eaccb25b828b65f?pvs=21)**: Detailed performance analyses

### Theoretical Foundation

Gyroscope implements algebraic structure through recursive reasoning:

**Gyrogroup Properties:**
- G = {all four-state reasoning cycles with recursive memory}
- Binary operation: a âŠ• b = sequential composition of reasoning cycles
- Identity element: bare governance cycle (@ only)
- Inverse operation: integrative cycle reversal
- Gyration: phase-shift transformation across cycles

This algebraic foundation ensures consistent reasoning structure while preserving content flexibility.

---

## ðŸ“„ Research Publication

**AI Quality Governance**  
*Human Data Evaluation and Responsible AI Behavior Alignment*

[![View Publication](https://img.shields.io/badge/ðŸ“–%20View%20Publication-4A90E2?style=for-the-badge&labelColor=2F2F2F)](http://doi.org/10.17613/43wc1-mvn58)

---

## ðŸ“– Citation

**For The Human Mark:**
```bibtex
@misc{thehumanmark2025,
  title={The Human Mark: Authority-Agency Framework for AI Alignment},
  author={Korompilias, Basil},
  year={2025},
  publisher={GYROGOVERNANCE},
   doi={10.5281/zenodo.17622836},
   url={https://doi.org/10.5281/zenodo.17622836},
  note={Coordination standard for AI safety and governance across capability levels}
}
```

**For Gyroscope Protocol:**
```bibtex
@misc{gyroscope2025,
  title={Gyroscope: Inductive Reasoning Protocol for AI Alignment},
  author={Korompilias, Basil},
  year={2025},
  publisher={GYROGOVERNANCE},
   doi={10.5281/zenodo.17622837},
   url={https://doi.org/10.5281/zenodo.17622837},
  note={Meta-reasoning protocol with empirical performance validation}
}
```

---

## ðŸ“„ License

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).

Attribution required. Derivative works must be distributed under the same license.

Author: Basil Korompilias.

---

<div style="border: 1px solid #ccc; padding: 1em; font-size: 0.6em; background-color: #f9f9f9; border-radius: 6px; line-height: 1.5;">
  <p><strong>ðŸ¤– AI Disclosure</strong></p>
  <p>All software architecture, design, implementation, documentation, and evaluation frameworks in this project were authored and engineered by its Author.</p>
  <p>Artificial intelligence was employed solely as a technical assistant, limited to code drafting, formatting, verification, and editorial services, always under direct human supervision.</p>
  <p>All foundational ideas, design decisions, and conceptual frameworks originate from the Author.</p>
  <p>Responsibility for the validity, coherence, and ethical direction of this project remains fully human.</p>
  <p><strong>Acknowledgements:</strong><br>
  This project benefited from AI language model services accessed through LMArena, Cursor IDE, OpenAI (ChatGPT), Anthropic (Claude), XAI (Grok), Deepseek, and Google (Gemini).</p>
</div>